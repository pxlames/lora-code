# 微调技术学习心得

## 已掌握内容

我已经系统学习了大语言模型的微调技术，主要包括以下内容：

- **SFT（Supervised Fine-Tuning）**：有监督微调，掌握了基本流程和数据准备方法。
- **PEFT（Parameter-Efficient Fine-Tuning）**：参数高效微调，重点学习了以下方法：
  - **LoRA（Low-Rank Adaptation）**：了解了其原理和在大模型微调中的应用。
  - **QLoRA**：掌握了量化与低秩结合的高效微调方式。
  - **peft库**：熟悉了 peft 库的使用方法，能够灵活调用其各类微调方案。
- **Xtuner**：已经接触并初步使用过 Xtuner 工具，了解其在微调流程中的作用。

## 后续学习计划

接下来，我准备进一步学习和掌握以下内容：

- **Unsloth**：探索更高效的微调实现方案。
- **llama_factory**：低代码平台。
- **Deepspeed 分布式训练框架**：学习大规模分布式训练与推理的实现方法，提升训练效率和模型规模。

## 目标

通过持续学习和实践，进一步提升大模型微调与部署能力，掌握主流和前沿的高效微调技术，能够独立完成大模型的定制化训练与优化。
