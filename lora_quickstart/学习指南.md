# LoRA微调学习指南

## 🎯 学习目标

通过这个项目，你将学会：
- LoRA（Low-Rank Adaptation）的原理和实现
- 如何使用PEFT库进行参数高效微调
- 中文指令微调的最佳实践
- 模型评估和可视化的方法
- 从零开始构建一个完整的微调项目

## 📚 核心概念

### 1. LoRA原理
LoRA是一种参数高效微调方法，通过低秩矩阵分解来近似全参数微调的效果：

```
原始权重: W ∈ R^(d×k)
LoRA分解: W + ΔW = W + BA
其中: B ∈ R^(d×r), A ∈ R^(r×k), r << min(d,k)
```

**优势：**
- 大幅减少可训练参数（通常减少99%+）
- 训练速度快，内存占用少
- 可以轻松切换不同的LoRA适配器

### 2. 关键参数
- `r`: LoRA秩，控制参数量和表达能力
- `lora_alpha`: 缩放参数，影响学习率
- `target_modules`: 目标模块，决定对哪些层应用LoRA

## 🛠️ 实践步骤

### 第一步：环境准备
```bash
# 安装依赖
pip install -r requirements.txt

# 检查GPU（可选但推荐）
python -c "import torch; print(f'CUDA available: {torch.cuda.is_available()}')"
```

### 第二步：数据准备
```bash
# 创建数据集
python data/prepare_data.py

# 查看数据格式
head -20 data/chinese_instructions.json
```

**数据格式说明：**
```json
{
  "instruction": "用户指令",
  "input": "可选输入",
  "output": "期望输出"
}
```

### 第三步：模型训练
```bash
# 开始训练
python training/train.py

# 或者使用快速开始脚本
python quick_start.py
```

**训练监控：**
- 使用Wandb查看训练曲线
- 观察loss下降趋势
- 监控GPU内存使用

### 第四步：模型评估
```bash
# 评估模型性能
python training/evaluate.py --model_path outputs

# 查看评估结果
cat outputs/evaluation_results.json
```

**评估指标：**
- 成功率：成功生成的样本比例
- 平均相似度：生成文本与期望文本的相似度
- 生成时间：平均生成时间
- 生成长度：平均生成长度

### 第五步：结果可视化
```bash
# 生成可视化图表
python visualization/plot_results.py

# 查看生成的图表
ls outputs/*.png
```

### 第六步：模型演示
```bash
# 交互式演示
python examples/demo.py --model_path outputs --mode interactive

# 批量演示
python examples/demo.py --model_path outputs --mode batch
```

## 🔧 参数调优技巧

### 1. LoRA参数调优
```yaml
lora:
  r: 16          # 增加r提高表达能力，但增加参数量
  lora_alpha: 32 # 通常设为r的2倍
  target_modules: ["q_proj", "v_proj"] # 只对注意力层应用LoRA
```

**调优建议：**
- 从小r开始（8-16），逐步增加
- 优先对注意力层应用LoRA
- 根据任务复杂度调整r值

### 2. 训练参数调优
```yaml
training:
  learning_rate: 2e-4    # 通常比全量微调大
  batch_size: 4          # 根据GPU内存调整
  num_epochs: 3          # 避免过拟合
  warmup_ratio: 0.1      # 学习率预热
```

### 3. 数据质量优化
- **指令多样性**：包含不同类型的任务
- **输出质量**：确保输出格式一致
- **数据量**：1000-10000样本通常足够

## 📊 性能分析

### 1. 参数量对比
```
全量微调: ~500M 参数
LoRA (r=16): ~1M 参数 (减少99.8%)
LoRA (r=32): ~2M 参数 (减少99.6%)
```

### 2. 训练效率
- **时间**：LoRA训练时间约为全量微调的1/3
- **内存**：LoRA内存占用约为全量微调的1/4
- **存储**：LoRA权重文件通常只有几MB

### 3. 性能权衡
- **r值越大**：表达能力越强，但参数量增加
- **目标模块越多**：效果越好，但训练成本增加
- **数据质量越高**：微调效果越好

## 🚀 进阶技巧

### 1. 多任务学习
```python
# 为不同任务训练不同的LoRA适配器
task1_lora = PeftModel.from_pretrained(model, "task1_lora")
task2_lora = PeftModel.from_pretrained(model, "task2_lora")
```

### 2. 渐进式训练
```python
# 先训练低秩，再增加秩
# 第一阶段：r=8
# 第二阶段：r=16
# 第三阶段：r=32
```

### 3. 知识蒸馏
```python
# 使用大模型指导小模型
teacher_model = load_large_model()
student_model = load_small_model_with_lora()
```

## 🐛 常见问题

### 1. 训练不收敛
**原因：** 学习率过高、数据质量差、r值过小
**解决：** 降低学习率、检查数据、增加r值

### 2. 生成质量差
**原因：** 数据量不足、指令格式不一致、模型容量不够
**解决：** 增加数据、统一格式、调整r值

### 3. 内存不足
**原因：** batch_size过大、序列长度过长
**解决：** 减小batch_size、使用梯度累积、减少max_length

### 4. 训练速度慢
**原因：** 使用CPU、数据加载慢、模型过大
**解决：** 使用GPU、增加dataloader_workers、使用更小的模型

## 📈 实验建议

### 1. 基线实验
- 记录原始模型性能
- 测试不同r值的效果
- 比较不同target_modules的选择

### 2. 消融实验
- 固定其他参数，只改变r值
- 测试不同学习率的影响
- 比较不同数据量的效果

### 3. 对比实验
- LoRA vs 全量微调
- 不同LoRA配置的对比
- 不同数据集的对比

## 🎓 学习资源

### 1. 论文阅读
- [LoRA: Low-Rank Adaptation of Large Language Models](https://arxiv.org/abs/2106.09685)
- [Parameter-Efficient Transfer Learning for NLP](https://arxiv.org/abs/1902.00751)

### 2. 代码库
- [PEFT库](https://github.com/huggingface/peft)
- [Transformers库](https://github.com/huggingface/transformers)

### 3. 在线资源
- [Hugging Face LoRA教程](https://huggingface.co/docs/peft/conceptual_guides/lora)
- [LoRA微调实践指南](https://github.com/microsoft/LoRA)

## 🏆 项目总结

通过这个项目，你应该能够：

1. **理解LoRA原理**：掌握低秩适应的工作机制
2. **实现微调流程**：从数据准备到模型部署的完整流程
3. **优化模型性能**：通过参数调优提升模型效果
4. **分析实验结果**：使用可视化工具分析模型性能
5. **解决实际问题**：具备独立完成LoRA微调项目的能力

记住：**实践是最好的学习方式**，多尝试不同的配置，观察结果变化，积累经验！

---

**祝你学习愉快！** 🎉
